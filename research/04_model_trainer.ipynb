{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Desktop/pixi_hr_project/pixi_hr/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Desktop/pixi_hr_project/pixi_hr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update config.yaml first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1382475702.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    model_trainer:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Model Trainer Configuration\n",
    "\n",
    "model_trainer:\n",
    "  # Path to the root directory where model trainer artifacts are stored.\n",
    "  root_dir: artifacts/model_trainer\n",
    "  \n",
    "  # Location of the training dataset (in this case, a CSV file).\n",
    "  train_data_path: artifacts/data_transformation/train.csv\n",
    "  \n",
    "  # Location of the testing dataset (in this case, a CSV file).\n",
    "  test_data_path: artifacts/data_transformation/test.csv\n",
    "  \n",
    "  # Name of the serialized trained model to be saved.\n",
    "  model_name: model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    \"\"\"\n",
    "    Configuration entity for the Model Trainer.\n",
    "\n",
    "    Attributes:\n",
    "    - root_dir: Directory where model training artifacts will be stored.\n",
    "    - train_data_path: Path to the training data file.\n",
    "    - test_data_path: Path to the test data file.\n",
    "    - model_name: Name of the model file to be saved.\n",
    "    - alpha: Regularization strength for the ElasticNet model. \n",
    "             Combines the L1 and L2 penalties. Higher values specify stronger regularization.\n",
    "    - l1_ratio: The mix between L1 and L2 regularization. \n",
    "                0 <= l1_ratio <= 1. 0 corresponds to L2 (Ridge) and 1 to L1 (Lasso).\n",
    "    - target_column: Name of the column in the dataset that represents the target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    alpha: float\n",
    "    l1_ratio: float\n",
    "    target_column: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update parameters in params.yaml where we can hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ElasticNet:\n",
    "    alpha: 0.5\n",
    "    l1_ratio: 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pixi_hr.constants import *\n",
    "from src.pixi_hr.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    The ConfigurationManager class is responsible for managing configurations from various YAML files.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Loaded configuration details.\n",
    "        params (dict): Loaded parameter details.\n",
    "        schema (dict): Loaded schema details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,    # Path to the main configuration YAML file\n",
    "                 params_filepath=PARAMS_FILE_PATH,    # Path to the parameters YAML file\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):   # Path to the schema YAML file\n",
    "        \"\"\"\n",
    "        Initializes the ConfigurationManager and loads configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (Path): Path to the main configuration YAML file.\n",
    "            params_filepath (Path): Path to the parameters YAML file.\n",
    "            schema_filepath (Path): Path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load configurations, parameters, and schema details from their respective YAML files\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        # Create root directory for storing all artifacts, as specified in the configuration\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        \"\"\"\n",
    "        Fetches the Model Trainer Configuration.\n",
    "\n",
    "        Returns:\n",
    "            ModelTrainerConfig: A dataclass instance containing the model trainer configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract model trainer configuration and parameters for ElasticNet\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        # Create the directory where model training artifacts will be stored\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # Create an instance of the ModelTrainerConfig dataclass using the extracted configuration and parameters\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            alpha=params.alpha,\n",
    "            l1_ratio=params.l1_ratio,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-23 16:05:45,964: 160: numexpr.utils: INFO: utils:  NumExpr defaulting to 8 threads.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "from pixi_hr import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    ModelTrainer Class responsible for training a predictive model.\n",
    "    \n",
    "    Attributes:\n",
    "        config (ModelTrainerConfig): Configuration for the model training.\n",
    "    \n",
    "    Methods:\n",
    "        load_data: Load the training and testing datasets.\n",
    "        preprocess_data: Preprocesses the data by dropping specific columns and splitting into features and target.\n",
    "        scale_features: Scales the features using StandardScaler.\n",
    "        train_model: Trains the model using the training data.\n",
    "        save_model: Saves the trained model to a specified directory.\n",
    "        main: Orchestrates the model training process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTrainer class with a configuration.\n",
    "\n",
    "        Args:\n",
    "            config (ModelTrainerConfig): Configuration for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load training and test data.\"\"\"\n",
    "        self.train_data = pd.read_csv(self.config.train_data_path)\n",
    "        self.test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Drop unwanted columns and split data into features and target.\"\"\"\n",
    "        columns_to_drop = ['date_of_job_post', 'job_link', 'job_qualifications', \n",
    "                           'job_description', 'job_summary', 'date_of_job_post_temp']\n",
    "        \n",
    "        self.train_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        self.test_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "        self.train_x = self.train_data.drop([self.config.target_column], axis=1)\n",
    "        self.train_y = self.train_data[self.config.target_column]\n",
    "\n",
    "        self.test_x = self.test_data.drop([self.config.target_column], axis=1)\n",
    "        self.test_y = self.test_data[self.config.target_column]\n",
    "\n",
    "    def scale_features(self):\n",
    "        \"\"\"Scale the features using StandardScaler.\"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        self.train_x = scaler.fit_transform(self.train_x)\n",
    "        self.test_x = scaler.transform(self.test_x)\n",
    "\n",
    "    def train_model(self, model):\n",
    "        \"\"\"\n",
    "        Train the model using the training data.\n",
    "\n",
    "        Args:\n",
    "            model (model instance): Machine learning model to be trained.\n",
    "        \n",
    "        Returns:\n",
    "            model (model instance): Trained machine learning model.\n",
    "        \"\"\"\n",
    "        model.fit(self.train_x, self.train_y)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        \"\"\"\n",
    "        Save the trained model to a specified directory.\n",
    "\n",
    "        Args:\n",
    "            model (model instance): Trained machine learning model to save.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            joblib.dump(model, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "            logger.info(f\"Model saved successfully at {os.path.join(self.config.root_dir, self.config.model_name)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving the model: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"Main execution method that orchestrates the model training process.\"\"\"\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.scale_features()\n",
    "        lr = ElasticNet(alpha=self.config.alpha, l1_ratio=self.config.l1_ratio, random_state=44)\n",
    "        trained_model = self.train_model(lr)\n",
    "        self.save_model(trained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixi_hr import logger\n",
    "from pixi_hr.config.configuration import ConfigurationManager\n",
    "from pixi_hr.components.model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-23 16:56:20,497: 48: pixi_hr_project_logger: INFO: 3263865135:  >>>>>> Stage: Model Training Stage started <<<<<<]\n",
      "[2023-08-23 16:56:20,505: 41: pixi_hr_project_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-08-23 16:56:20,507: 41: pixi_hr_project_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-08-23 16:56:20,508: 41: pixi_hr_project_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-08-23 16:56:20,509: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-08-23 16:56:20,509: 33: pixi_hr_project_logger: INFO: 3263865135:  Starting the Model Training Pipeline]\n",
      "[2023-08-23 16:56:20,509: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "[2023-08-23 16:56:20,553: 73: pixi_hr_project_logger: INFO: 965417682:  Model saved successfully at artifacts/model_trainer/model.joblib]\n",
      "[2023-08-23 16:56:20,557: 44: pixi_hr_project_logger: INFO: 3263865135:  Model Training Pipeline Completed Successfully.]\n",
      "[2023-08-23 16:56:20,559: 51: pixi_hr_project_logger: INFO: 3263865135:  >>>>>> Stage Model Training Stage completed <<<<<< \n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "class ModelTrainerPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline class for the model training phase.\n",
    "\n",
    "    This pipeline performs the following steps:\n",
    "    1. Initializes configuration management.\n",
    "    2. Fetches the model training configuration.\n",
    "    3. Initializes the ModelTrainer component.\n",
    "    4. Trains the model using the training data.\n",
    "\n",
    "    Attributes:\n",
    "    - STAGE_NAME (str): Name of the stage (used for logging purposes).\n",
    "    - config (ConfigurationManager): Instance of the ConfigurationManager.\n",
    "    \n",
    "    Methods:\n",
    "    - main(): Executes the main functionality of the ModelTrainerPipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    STAGE_NAME = \"Model Training Stage\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTrainerPipeline.\n",
    "        Sets up the configuration manager.\n",
    "        \"\"\"\n",
    "        # Step 1: Initialize Configuration Manager\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"\n",
    "        Executes the main functionality of the ModelTrainerPipeline.\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting the Model Training Pipeline\")\n",
    "\n",
    "        # Step 2: Fetch Model Training Configuration\n",
    "        model_trainer_config = self.config_manager.get_model_trainer_config()\n",
    "\n",
    "        # Step 3: Initialize Model Trainer Component\n",
    "        model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "\n",
    "        # Step 4: Train Model\n",
    "        model_trainer.main()\n",
    "\n",
    "        logger.info(\"Model Training Pipeline Completed Successfully.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage: {ModelTrainerPipeline.STAGE_NAME} started <<<<<<\")\n",
    "        model_trainer_pipeline = ModelTrainerPipeline()\n",
    "        model_trainer_pipeline.main()\n",
    "        logger.info(f\">>>>>> Stage {ModelTrainerPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error encountered during the {ModelTrainerPipeline.STAGE_NAME}: {e}\")\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixi_hr_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
