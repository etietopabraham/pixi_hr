{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Desktop/pixi_hr_project/pixi_hr/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Desktop/pixi_hr_project/pixi_hr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update config.yaml first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Model Trainer Configuration\n",
    "\n",
    "model_trainer:\n",
    "  # Path to the root directory where model trainer artifacts are stored.\n",
    "  root_dir: artifacts/model_trainer\n",
    "  \n",
    "  # Location of the training dataset (in this case, a CSV file).\n",
    "  train_data_path: artifacts/data_transformation/train_data.csv\n",
    "  \n",
    "  # Location of the testing dataset (in this case, a CSV file).\n",
    "  test_data_path: artifacts/data_transformation/test_data.csv\n",
    "  \n",
    "  # Name of the serialized trained model to be saved.\n",
    "  model_name: model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    target_column: str\n",
    "    model_name: str\n",
    "    model_type: str\n",
    "    model_params: dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update parameters in params.yaml where we can hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ElasticNet:\n",
    "    alpha: 0.5\n",
    "    l1_ratio: 0.7\n",
    "\n",
    "RandomForest:\n",
    "  n_estimators: 100\n",
    "  max_depth: None\n",
    "  min_samples_split: 2\n",
    "  min_samples_leaf: 1\n",
    "  max_features: 'auto'\n",
    "  random_state: 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pixi_hr.constants import *\n",
    "from src.pixi_hr.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    The ConfigurationManager class is responsible for managing configurations from various YAML files.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Loaded configuration details.\n",
    "        params (dict): Loaded parameter details.\n",
    "        schema (dict): Loaded schema details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,    # Path to the main configuration YAML file\n",
    "                 params_filepath=PARAMS_FILE_PATH,    # Path to the parameters YAML file\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):   # Path to the schema YAML file\n",
    "        \"\"\"\n",
    "        Initializes the ConfigurationManager and loads configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (Path): Path to the main configuration YAML file.\n",
    "            params_filepath (Path): Path to the parameters YAML file.\n",
    "            schema_filepath (Path): Path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load configurations, parameters, and schema details from their respective YAML files\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        # Convert 'None' string to Python None object for specific parameters\n",
    "        for param, value in self.params['RandomForest'].items():\n",
    "            if value == 'None':\n",
    "                self.params['RandomForest'][param] = None\n",
    "\n",
    "\n",
    "        # Create root directory for storing all artifacts, as specified in the configuration\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self, chosen_model_type=\"RandomForest\") -> ModelTrainerConfig:\n",
    "        \"\"\"\n",
    "        Fetches the Model Trainer Configuration based on the chosen model type.\n",
    "\n",
    "        Args:\n",
    "        - chosen_model_type (str): The desired model type (either \"ElasticNet\" or \"RandomForest\").\n",
    "\n",
    "        Returns:\n",
    "            ModelTrainerConfig: A dataclass instance containing the model trainer configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract model trainer configuration\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        # Depending on the chosen model type, fetch the respective parameters\n",
    "        if chosen_model_type == \"ElasticNet\":\n",
    "            params = self.params.ElasticNet\n",
    "        elif chosen_model_type == \"RandomForest\":\n",
    "            params = self.params.RandomForest\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {chosen_model_type}\")\n",
    "        \n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        # Create the directory where model training artifacts will be stored\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # Create an instance of the ModelTrainerConfig dataclass using the extracted configuration and parameters\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            target_column=schema.name,\n",
    "            model_type=chosen_model_type,\n",
    "            model_params=params\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "from pixi_hr import logger\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    ModelTrainer Class responsible for training a predictive model.\n",
    "    \n",
    "    Attributes:\n",
    "        config (ModelTrainerConfig): Configuration for the model training.\n",
    "    \n",
    "    Methods:\n",
    "        load_data: Load the training and testing datasets.\n",
    "        preprocess_data: Preprocesses the data by dropping specific columns and splitting into features and target.\n",
    "        scale_features: Scales the features using StandardScaler.\n",
    "        train_model: Trains the model using the training data.\n",
    "        save_model: Saves the trained model to a specified directory.\n",
    "        main: Orchestrates the model training process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTrainer class with a configuration.\n",
    "\n",
    "        Args:\n",
    "            config (ModelTrainerConfig): Configuration for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load training and test data.\"\"\"\n",
    "        self.train_data = pd.read_csv(self.config.train_data_path)\n",
    "        self.test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "    def print_data(self):\n",
    "        print(\"Scaled Train Features\")\n",
    "        print(pd.DataFrame(self.train_x).head())\n",
    "        print(\"Scaled Test Features\")\n",
    "        print(pd.DataFrame(self.test_x).head())\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Drop unwanted columns and split data into features and target.\"\"\"\n",
    "        \n",
    "        # Filter out columns that are not related to job_qualifications (i.e., prefixed by 'qual_')\n",
    "        qualification_columns = [col for col in self.train_data.columns if col.startswith('qual_')]\n",
    "        \n",
    "        self.train_x = self.train_data[qualification_columns]\n",
    "        self.train_y = self.train_data[self.config.target_column]\n",
    "\n",
    "        self.test_x = self.test_data[qualification_columns]\n",
    "        self.test_y = self.test_data[self.config.target_column]\n",
    "\n",
    "\n",
    "    def scale_features(self):\n",
    "        \"\"\"Scale the features using StandardScaler.\"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        self.train_x = scaler.fit_transform(self.train_x)\n",
    "        self.test_x = scaler.transform(self.test_x)\n",
    "\n",
    "    def train_model(self, model):\n",
    "        \"\"\"\n",
    "        Train the model using the training data.\n",
    "\n",
    "        Args:\n",
    "            model (model instance): Machine learning model to be trained.\n",
    "        \n",
    "        Returns:\n",
    "            model (model instance): Trained machine learning model.\n",
    "        \"\"\"\n",
    "        model.fit(self.train_x, self.train_y)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        \"\"\"\n",
    "        Save the trained model to a specified directory.\n",
    "\n",
    "        Args:\n",
    "            model (model instance): Trained machine learning model to save.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            joblib.dump(model, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "            logger.info(f\"Model saved successfully at {os.path.join(self.config.root_dir, self.config.model_name)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving the model: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def main(self):\n",
    "\n",
    "        \"\"\"Main execution method that orchestrates the model training process.\"\"\"\n",
    "        \n",
    "        logger.info(\"Loading data...\")\n",
    "        self.load_data()\n",
    "        \n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        self.preprocess_data()\n",
    "\n",
    "        # Depending on the model type from the configuration, initialize the appropriate model\n",
    "        if self.config.model_type == \"ElasticNet\":\n",
    "            model = ElasticNet(\n",
    "                alpha=self.config.model_params[\"alpha\"], \n",
    "                l1_ratio=self.config.model_params[\"l1_ratio\"], \n",
    "                random_state=44\n",
    "            )\n",
    "        elif self.config.model_type == \"RandomForest\":\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=self.config.model_params[\"n_estimators\"],\n",
    "                max_depth=self.config.model_params[\"max_depth\"],\n",
    "                min_samples_split=self.config.model_params[\"min_samples_split\"],\n",
    "                min_samples_leaf=self.config.model_params[\"min_samples_leaf\"],\n",
    "                max_features=self.config.model_params[\"max_features\"],\n",
    "                random_state=self.config.model_params[\"random_state\"]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {self.config.model_type}\")\n",
    "        \n",
    "        trained_model = self.train_model(model)\n",
    "        \n",
    "        logger.info(\"Saving the trained model...\")\n",
    "        self.save_model(trained_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troble shooting scaling process and hyperparamters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-26 13:40:58,310: 41: pixi_hr_project_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-08-26 13:40:58,312: 41: pixi_hr_project_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-08-26 13:40:58,314: 41: pixi_hr_project_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-08-26 13:40:58,314: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-08-26 13:40:58,315: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "Scaled Train Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833  4.884377   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0  9.273618 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "Scaled Test Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453  5.813777 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "model_trainer_config = config_manager.get_model_trainer_config()\n",
    "model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "model_trainer.load_data()\n",
    "model_trainer.preprocess_data()\n",
    "model_trainer.scale_features()\n",
    "model_trainer.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-26 13:41:16,800: 41: pixi_hr_project_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-08-26 13:41:16,804: 41: pixi_hr_project_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-08-26 13:41:16,806: 41: pixi_hr_project_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-08-26 13:41:16,806: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-08-26 13:41:16,807: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "Scaled Train Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833  4.884377   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0  9.273618 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "Scaled Test Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453  5.813777 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Parameters: {'alpha': 3.8025826818609807, 'l1_ratio': 0.08974338945661875}\n",
      "Best Score: -0.028057691735429203\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "model_trainer_config = config_manager.get_model_trainer_config()\n",
    "model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "model_trainer.load_data()\n",
    "model_trainer.preprocess_data()\n",
    "model_trainer.scale_features()\n",
    "model_trainer.print_data()\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# 1. Define the Parameter Grid:\n",
    "param_dist = {\n",
    "    'alpha': uniform(loc=0, scale=4), # You might want to refine the scale based on domain knowledge\n",
    "    'l1_ratio': uniform(loc=0, scale=1)\n",
    "}\n",
    "\n",
    "# 2. Setup the Randomized Search:\n",
    "elastic_net = ElasticNet()\n",
    "random_search = RandomizedSearchCV(\n",
    "    elastic_net, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=-1, \n",
    "    # scoring='r2'\n",
    ")\n",
    "\n",
    "# 3. Fit the Randomized Search:\n",
    "# Assuming you have train_x and train_y from your previous steps\n",
    "random_search.fit(model_trainer.train_x, model_trainer.train_y)\n",
    "\n",
    "# 4. Inspect Results:\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixi_hr import logger\n",
    "from pixi_hr.config.configuration import ConfigurationManager\n",
    "from pixi_hr.components.model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-26 19:17:13,968: 48: pixi_hr_project_logger: INFO: 3263865135:  >>>>>> Stage: Model Training Stage started <<<<<<]\n",
      "[2023-08-26 19:17:13,976: 41: pixi_hr_project_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-08-26 19:17:13,978: 41: pixi_hr_project_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-08-26 19:17:13,980: 41: pixi_hr_project_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-08-26 19:17:13,981: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-08-26 19:17:13,982: 33: pixi_hr_project_logger: INFO: 3263865135:  Starting the Model Training Pipeline]\n",
      "[2023-08-26 19:17:13,982: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "[2023-08-26 19:17:13,983: 89: pixi_hr_project_logger: INFO: 4289294302:  Loading data...]\n",
      "[2023-08-26 19:17:14,033: 92: pixi_hr_project_logger: INFO: 4289294302:  Preprocessing data...]\n",
      "[2023-08-26 19:17:14,187: 116: pixi_hr_project_logger: INFO: 4289294302:  Saving the trained model...]\n",
      "[2023-08-26 19:17:14,205: 80: pixi_hr_project_logger: INFO: 4289294302:  Model saved successfully at artifacts/model_trainer/model.joblib]\n",
      "[2023-08-26 19:17:14,205: 44: pixi_hr_project_logger: INFO: 3263865135:  Model Training Pipeline Completed Successfully.]\n",
      "[2023-08-26 19:17:14,205: 51: pixi_hr_project_logger: INFO: 3263865135:  >>>>>> Stage Model Training Stage completed <<<<<< \n",
      "\n",
      "x==========x]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/pixi_hr_environment/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "class ModelTrainerPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline class for the model training phase.\n",
    "\n",
    "    This pipeline performs the following steps:\n",
    "    1. Initializes configuration management.\n",
    "    2. Fetches the model training configuration.\n",
    "    3. Initializes the ModelTrainer component.\n",
    "    4. Trains the model using the training data.\n",
    "\n",
    "    Attributes:\n",
    "    - STAGE_NAME (str): Name of the stage (used for logging purposes).\n",
    "    - config (ConfigurationManager): Instance of the ConfigurationManager.\n",
    "    \n",
    "    Methods:\n",
    "    - main(): Executes the main functionality of the ModelTrainerPipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    STAGE_NAME = \"Model Training Stage\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTrainerPipeline.\n",
    "        Sets up the configuration manager.\n",
    "        \"\"\"\n",
    "        # Step 1: Initialize Configuration Manager\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"\n",
    "        Executes the main functionality of the ModelTrainerPipeline.\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting the Model Training Pipeline\")\n",
    "\n",
    "        # Step 2: Fetch Model Training Configuration\n",
    "        model_trainer_config = self.config_manager.get_model_trainer_config()\n",
    "\n",
    "        # Step 3: Initialize Model Trainer Component\n",
    "        model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "\n",
    "        # Step 4: Train Model\n",
    "        model_trainer.main()\n",
    "\n",
    "        logger.info(\"Model Training Pipeline Completed Successfully.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage: {ModelTrainerPipeline.STAGE_NAME} started <<<<<<\")\n",
    "        model_trainer_pipeline = ModelTrainerPipeline()\n",
    "        model_trainer_pipeline.main()\n",
    "        logger.info(f\">>>>>> Stage {ModelTrainerPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error encountered during the {ModelTrainerPipeline.STAGE_NAME}: {e}\")\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixi_hr_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
