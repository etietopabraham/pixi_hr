{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Desktop/pixi_hr_project/pixi_hr/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Desktop/pixi_hr_project/pixi_hr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update config.yaml first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Model Trainer Configuration\n",
    "\n",
    "model_trainer:\n",
    "  # Path to the root directory where model trainer artifacts are stored.\n",
    "  root_dir: artifacts/model_trainer\n",
    "  \n",
    "  # Location of the training dataset (in this case, a CSV file).\n",
    "  train_data_path: artifacts/data_transformation/train_data.csv\n",
    "  \n",
    "  # Location of the testing dataset (in this case, a CSV file).\n",
    "  test_data_path: artifacts/data_transformation/test_data.csv\n",
    "  \n",
    "  # Name of the serialized trained model to be saved.\n",
    "  model_name: model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    \"\"\"\n",
    "    Configuration entity for the Model Trainer.\n",
    "\n",
    "    Attributes:\n",
    "    - root_dir: Directory where model training artifacts will be stored.\n",
    "    - train_data_path: Path to the training data file.\n",
    "    - test_data_path: Path to the test data file.\n",
    "    - model_name: Name of the model file to be saved.\n",
    "    - alpha: Regularization strength for the ElasticNet model. \n",
    "             Combines the L1 and L2 penalties. Higher values specify stronger regularization.\n",
    "    - l1_ratio: The mix between L1 and L2 regularization. \n",
    "                0 <= l1_ratio <= 1. 0 corresponds to L2 (Ridge) and 1 to L1 (Lasso).\n",
    "    - target_column: Name of the column in the dataset that represents the target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    alpha: float\n",
    "    l1_ratio: float\n",
    "    target_column: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update parameters in params.yaml where we can hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ElasticNet:\n",
    "    alpha: 0.5\n",
    "    l1_ratio: 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pixi_hr.constants import *\n",
    "from src.pixi_hr.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    The ConfigurationManager class is responsible for managing configurations from various YAML files.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Loaded configuration details.\n",
    "        params (dict): Loaded parameter details.\n",
    "        schema (dict): Loaded schema details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,    # Path to the main configuration YAML file\n",
    "                 params_filepath=PARAMS_FILE_PATH,    # Path to the parameters YAML file\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):   # Path to the schema YAML file\n",
    "        \"\"\"\n",
    "        Initializes the ConfigurationManager and loads configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (Path): Path to the main configuration YAML file.\n",
    "            params_filepath (Path): Path to the parameters YAML file.\n",
    "            schema_filepath (Path): Path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load configurations, parameters, and schema details from their respective YAML files\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        # Create root directory for storing all artifacts, as specified in the configuration\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        \"\"\"\n",
    "        Fetches the Model Trainer Configuration.\n",
    "\n",
    "        Returns:\n",
    "            ModelTrainerConfig: A dataclass instance containing the model trainer configuration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract model trainer configuration and parameters for ElasticNet\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        # Create the directory where model training artifacts will be stored\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # Create an instance of the ModelTrainerConfig dataclass using the extracted configuration and parameters\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            alpha=params.alpha,\n",
    "            l1_ratio=params.l1_ratio,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "from pixi_hr import logger\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    ModelTrainer Class responsible for training a predictive model.\n",
    "    \n",
    "    Attributes:\n",
    "        config (ModelTrainerConfig): Configuration for the model training.\n",
    "    \n",
    "    Methods:\n",
    "        load_data: Load the training and testing datasets.\n",
    "        preprocess_data: Preprocesses the data by dropping specific columns and splitting into features and target.\n",
    "        scale_features: Scales the features using StandardScaler.\n",
    "        train_model: Trains the model using the training data.\n",
    "        save_model: Saves the trained model to a specified directory.\n",
    "        main: Orchestrates the model training process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTrainer class with a configuration.\n",
    "\n",
    "        Args:\n",
    "            config (ModelTrainerConfig): Configuration for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load training and test data.\"\"\"\n",
    "        self.train_data = pd.read_csv(self.config.train_data_path)\n",
    "        self.test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "    def print_data(self):\n",
    "        print(\"Scaled Train Features\")\n",
    "        print(pd.DataFrame(self.train_x).head())\n",
    "        print(\"Scaled Test Features\")\n",
    "        print(pd.DataFrame(self.test_x).head())\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Drop unwanted columns and split data into features and target.\"\"\"\n",
    "        \n",
    "        # Filter out columns that are not related to job_qualifications (i.e., prefixed by 'qual_')\n",
    "        qualification_columns = [col for col in self.train_data.columns if col.startswith('qual_')]\n",
    "        \n",
    "        self.train_x = self.train_data[qualification_columns]\n",
    "        self.train_y = self.train_data[self.config.target_column]\n",
    "\n",
    "        self.test_x = self.test_data[qualification_columns]\n",
    "        self.test_y = self.test_data[self.config.target_column]\n",
    "\n",
    "\n",
    "    def scale_features(self):\n",
    "        \"\"\"Scale the features using StandardScaler.\"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        self.train_x = scaler.fit_transform(self.train_x)\n",
    "        self.test_x = scaler.transform(self.test_x)\n",
    "\n",
    "    def train_model(self, model):\n",
    "        \"\"\"\n",
    "        Train the model using the training data.\n",
    "\n",
    "        Args:\n",
    "            model (model instance): Machine learning model to be trained.\n",
    "        \n",
    "        Returns:\n",
    "            model (model instance): Trained machine learning model.\n",
    "        \"\"\"\n",
    "        model.fit(self.train_x, self.train_y)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        \"\"\"\n",
    "        Save the trained model to a specified directory.\n",
    "\n",
    "        Args:\n",
    "            model (model instance): Trained machine learning model to save.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            joblib.dump(model, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "            logger.info(f\"Model saved successfully at {os.path.join(self.config.root_dir, self.config.model_name)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving the model: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"Main execution method that orchestrates the model training process.\"\"\"\n",
    "        \n",
    "        logger.info(\"Loading data...\")\n",
    "        self.load_data()\n",
    "        \n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        self.preprocess_data()\n",
    "        \n",
    "        logger.info(\"Scaling features...\")\n",
    "        self.scale_features()\n",
    "        \n",
    "        logger.info(\"Initializing and training the ElasticNet model...\")\n",
    "        lr = ElasticNet(alpha=self.config.alpha, l1_ratio=self.config.l1_ratio, random_state=44)\n",
    "        trained_model = self.train_model(lr)\n",
    "        \n",
    "        logger.info(\"Saving the trained model...\")\n",
    "        self.save_model(trained_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troble shooting scaling process and hyperparamters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-26 13:40:58,310: 41: pixi_hr_project_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-08-26 13:40:58,312: 41: pixi_hr_project_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-08-26 13:40:58,314: 41: pixi_hr_project_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-08-26 13:40:58,314: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-08-26 13:40:58,315: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "Scaled Train Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833  4.884377   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0  9.273618 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "Scaled Test Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453  5.813777 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "model_trainer_config = config_manager.get_model_trainer_config()\n",
    "model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "model_trainer.load_data()\n",
    "model_trainer.preprocess_data()\n",
    "model_trainer.scale_features()\n",
    "model_trainer.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-26 13:41:16,800: 41: pixi_hr_project_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-08-26 13:41:16,804: 41: pixi_hr_project_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-08-26 13:41:16,806: 41: pixi_hr_project_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-08-26 13:41:16,806: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-08-26 13:41:16,807: 64: pixi_hr_project_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "Scaled Train Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833  4.884377   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0  9.273618 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "Scaled Test Features\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "1 -0.132453  5.813777 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "2 -0.132453 -0.172005 -0.107833  2.147767 -0.318223 -0.107833 -0.204734   \n",
      "3 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "4 -0.132453 -0.172005 -0.107833 -0.465600 -0.318223 -0.107833 -0.204734   \n",
      "\n",
      "        7         8    9    ...       143       144       145       146  \\\n",
      "0 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "1 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "2 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "3 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "4 -0.172005 -0.076029  0.0  ... -0.076029 -0.076029 -0.076029 -0.132453   \n",
      "\n",
      "        147       148  149       150       151       152  \n",
      "0 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "1 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "2 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "3 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "4 -0.076029 -0.076029  0.0 -0.107833 -0.076029 -0.132453  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Parameters: {'alpha': 3.8025826818609807, 'l1_ratio': 0.08974338945661875}\n",
      "Best Score: -0.028057691735429203\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager()\n",
    "model_trainer_config = config_manager.get_model_trainer_config()\n",
    "model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "model_trainer.load_data()\n",
    "model_trainer.preprocess_data()\n",
    "model_trainer.scale_features()\n",
    "model_trainer.print_data()\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# 1. Define the Parameter Grid:\n",
    "param_dist = {\n",
    "    'alpha': uniform(loc=0, scale=4), # You might want to refine the scale based on domain knowledge\n",
    "    'l1_ratio': uniform(loc=0, scale=1)\n",
    "}\n",
    "\n",
    "# 2. Setup the Randomized Search:\n",
    "elastic_net = ElasticNet()\n",
    "random_search = RandomizedSearchCV(\n",
    "    elastic_net, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=-1, \n",
    "    # scoring='r2'\n",
    ")\n",
    "\n",
    "# 3. Fit the Randomized Search:\n",
    "# Assuming you have train_x and train_y from your previous steps\n",
    "random_search.fit(model_trainer.train_x, model_trainer.train_y)\n",
    "\n",
    "# 4. Inspect Results:\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixi_hr import logger\n",
    "from pixi_hr.config.configuration import ConfigurationManager\n",
    "from pixi_hr.components.model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainerPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline class for the model training phase.\n",
    "\n",
    "    This pipeline performs the following steps:\n",
    "    1. Initializes configuration management.\n",
    "    2. Fetches the model training configuration.\n",
    "    3. Initializes the ModelTrainer component.\n",
    "    4. Trains the model using the training data.\n",
    "\n",
    "    Attributes:\n",
    "    - STAGE_NAME (str): Name of the stage (used for logging purposes).\n",
    "    - config (ConfigurationManager): Instance of the ConfigurationManager.\n",
    "    \n",
    "    Methods:\n",
    "    - main(): Executes the main functionality of the ModelTrainerPipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    STAGE_NAME = \"Model Training Stage\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTrainerPipeline.\n",
    "        Sets up the configuration manager.\n",
    "        \"\"\"\n",
    "        # Step 1: Initialize Configuration Manager\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"\n",
    "        Executes the main functionality of the ModelTrainerPipeline.\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting the Model Training Pipeline\")\n",
    "\n",
    "        # Step 2: Fetch Model Training Configuration\n",
    "        model_trainer_config = self.config_manager.get_model_trainer_config()\n",
    "\n",
    "        # Step 3: Initialize Model Trainer Component\n",
    "        model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "\n",
    "        # Step 4: Train Model\n",
    "        model_trainer.main()\n",
    "\n",
    "        logger.info(\"Model Training Pipeline Completed Successfully.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage: {ModelTrainerPipeline.STAGE_NAME} started <<<<<<\")\n",
    "        model_trainer_pipeline = ModelTrainerPipeline()\n",
    "        model_trainer_pipeline.main()\n",
    "        logger.info(f\">>>>>> Stage {ModelTrainerPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error encountered during the {ModelTrainerPipeline.STAGE_NAME}: {e}\")\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixi_hr_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
